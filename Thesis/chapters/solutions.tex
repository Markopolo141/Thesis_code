\chapter{Existing solutions}
\label{cha:solutions}

While general discussions about the philosophy of distributive ethics is important, what is also important is the way in which those ideas can be made quantitatively precise.

In this chapter we consider the range of ways that some of the moral ideas about distribution have been mathemetised.
We highlight some of the most famous and relevent formulations, primarily because our development extends from them, and also ultimately contrasts against them.

We consider the following formulations:
\begin{itemize}
\item VCG,
\item nash bargaining with and without endogenous disagreement point,
\item cooperative game theory concepts such as the Core and Shapley Value,
\item and Locational Marginal Pricing.
\end{itemize}

We introduce, consider and discuss the qualities of each of these in turn, before we attempt a new synthesis in the next chapter \ref{}.
let us begin with the VCG mechanism.

\section{VCG}

In section \ref{sec:reference_points} we briefly explored the idea that people might be rewarded in proportion to their contribution to social welfare, above their absense individually.
While this idea may be simple, its mathematization has some suprising features.
The most direct mathemetisation of this idea, is the VCG mechanism with Clark pivot.

The VCG mechanism (with Clark pivot) is an allocation process where each player is payed money (or `transferable utility') equal to the impact that their presense has apon others (ie. their externality) in the decision process which selecting an outcome that maximises the sum of utility.
Let us explain with some mathematics:

\subsection{The minimal VCG process - with Clark pivot}
If we frame the VCG process as a bidding process of $n$ agents over a possible set of outcomes $X$.
We assume that every agent $i$ has a valuation (or utility) $v_i$ for any outcome in $X$:
$$ v_i~:~X\rightarrow \mathbb{R}_+ $$
The VCG bidding process asks every agent $i$ for their valuations and calculates the outcome that maximises the sum of the reported valuations:
$$ x^*(v) = \argmax_{x\in X}\sum_{i=1}^{n}v_i(x) $$
This outcome is implemented and the bidding process pays each agent $i$ the utility value $p_i$ (which may be positive or negative):
$$ p_i(v)=\sum_{j\ne i}v_j(x^*(v)) - \max_{x'\in X}\sum_{j\ne i}v_j(x') $$
And this value $p_i$ is the value that the player's presence adds to the utility of others minus the sum of their utility which would have been obtained in the player's absense - ie. the player's externality.

\subsection{Discussion about VCG}
The VCG mechanism with Clark pivot might be seen as an straightforward way of allocating ethical payments - as if a player's presence adds to the utility of others then they are postiviely compensated, and if a player's influence detracts from the utility of others then they are negatively compensated.

And since the set of possible outcomes $X$ are undefined it is possible to consider the application of the VCG mechanism in a variety of contexts, including electricity contexts.
So, for instance, VCG has been considered as a mechanism for allocating physical and monetary outcomes in various contexts within electricity networks, such as in auctions for bulk electricity generation, buying and selling energy storage products, and in procuring ancillary services \cite{FABRA200272, SESSA2017189, 8264596, 7512339}.

However VCG has some other particular properties, positive and negative.
The first and most notable property is that VCG mechanisms are \textit{truthfull} or \textit{incentive compatable}, in that no player can possibly gain from misreporting their valuations
in the event that the utility of the agents is quasilinear \cite{roberts1979characterization, Lavi2008}, ie. that their net utility is equal to their valuation of the outcome plus any transfers they recieve, and their utility $u_i$ has form:
$$ u_i = p_i(v)+v_i $$
And if incentive compatability induces players not to bid strategically, then it reduces the overhead of their participating in the system, and potentially eliminates a source of system instability.

Another interesting property is sometimes called \textit{individual rationality}, in that no agent (assuming quasilinear utility) will ever be left with a net negative utility. If the valuation of utility zero is regarded as the utility that would result if no VCG mechanism took place, hence the fact that VCG is invidually rational means that everybody is left being better than they would be otherwise if they did not participate in the mechanism. This quality of leaving all parties better off then they would be otherwise, is a possible component of ethical negotiation (see chapter \ref{}).

It is also directly \textit{efficient} in the sense that it actualises the utilitarian socially optimal solution $x^*(v)$.

However more negative features of VCG exist, one primary drawback of this mechanism is that it is not \textit{budget balanced}, in that it is possible for the amount of utility that is payed between the players might not sum to zero; and hence an implementation of VCG might require regular budget injection to maintain and/or sap money from between the participants.

Although VCG is incentive compatable for individual strategisers it is potentially vulnerabile to strategising coalitions, its implementation my involve imposing a lack of privacy for participants, and (depending on context) may also have high computational complexity.\cite{ShohamLeytonBrown09}

%Some of these properties are often held to be desirable, and others not. So, for instance, Truthfull mechanisms can be thought to induce all agents to report truthfully and hence might serve to eliminates the need for any strategising by them, which might otherwise be a source of system instability.
%Individually rationality is often viewed as a basic fairness property, in that nobody is left any worse-off for having participated in the system - which is a key factor in fairness as described by euvoluntary exchange (see section \ref{}).
%And budget balance is another important feature, in that the process can be maintained without budgetary injection, and without taking money from between the participants.
%And efficiency is straightforwardly a desirable property (see section \ref{}).

It is unfortunate, that some of these properties (incentive compatable, individually rational, budget balanced, and efficient) are known to be impossible to combine in the general case where there are a plurality of outcomes and the valuations are unrestricted, and these impossibility theorems are a component feature in the study of \textit{Mechanism Design}.%(find a good source, of, myerson satterthwaite theorem)

\subsection{VCG and Mechanism Design}

The VCG mechanism is a cornerstone component in the field of Mechanism Design, and there exist many good sources giving extended discussions on the field.\cite{37377}
But generally, Mechanism Design analyses systems which select social outcome/s based apon the strategic interaction of multiple parties with divergent interests.% and where each party has actual preferences over the possible outcomes, and also reported preferences over the outcomes.

One of the features of Mechanism design that the VCG mechanism illustrates, is the potential for considering and apprehending the way in which a system is likely to behave between rational individual strategising agents.
This possibility extends beyond VCG, particularly as it has been discovered that any system which is implemented between strategising agents can be altered such as to make it incentive compatable for them; this is called the revelation principle.\cite{RePEc:ecm:emetrp:v:41:y:1973:i:4:p:587-601}
The revelation principle has various formulations, but generally, for any system there will nash-equilibria in the interraction between the agents, and consequently an incentive compatable mechanism can be constructed by asking the agents for their true valuations and then implimenting the corresponding nash equilibria directly.
Unfortunately, it is sometimes the case that the nash-equilibria between strategising agents that have divergent interests may not coincide with what is socially optimal for them; and the far reaching effects of this are manifest in a variety of famous impossibility theorems in Mechanism Design. %And so, there are a series of strong impossibility proofs in mechanism design.

Some famous impossibility proofs in mechanism design include Arrow's impossibility theorem, the Myerson-Satterthwaite theorem, and the Gibbard-Satterthwaite theorem, which deal with impossibilities of socially optimal systems in voting, and in economic exchange where strategising is considered.

And so it is also proven that there is no easy alternative to VCG that is incentive compatabile, has unrestricted player preferences, and has individual rationality, and implements pareto-optimal outcome.\cite{YI201679}

There exist several avenues around the these proven impossibilities:

\subsection{Navigating around impossibilities in Mechanism Design}

%One of the fundamental problems of applying VCG to electricity networks is the budget-surplus that often results and where this money should go, particularly that if the money should go back into the participants in the network then it would destroy the incentive compatability that was essential to the scheme in the first place.


And there are several methods which have been developed to avert this issue:
\begin{enumerate}
    \item adding extra elements into consideration, such as baysean priors on preferences, and reducing incentive compatability to baysean incentive compatability (see section on bargaining)
    \item By throwing away consideration on the unrestrictedness of the player preferences, and by moving to other groves mechanisms which allow some redistribution of the surplus
    \item by sacrificing pareto-optimality in the choice of the social outcome while keeping budget balance and incentive compatability
\end{enumerate}

A groves mechanism chooses an outcome $o^*$ and defines a transfer $T_i$ to each agent $$T_i=\sum_{j\in I\setminus\{i\}}\hat{v}_j(o^*) - C_{-i}$$
where $C_{-i}$ is any value that is independent of $i$'s reported preferences.
VCG is a groves mechanism where $C_{-i}=\sum_{j\in I\setminus\{i\}}\hat{v}_j(o^*_{-i})$.


particularly the first is probably most interesting for our considerations, and is the source of the d'AVGA mechanism which allocates redistribution of the surplus bassed on baysean priors on player preferences.
The addition of baysean priors also has links to bargaining, particularly with the work of Meyerson, and his bargaining games.
Which in turn have been extened (by himself) to coalitional games, and also through some of his work to Harsanyi games. (CITE)
Particularly through the introduction of baysean considerations other schemes can redily be made to be incentive compatable.

However there are certain issues with supposing accurately known baysean priors (particularly if they are learnt from past behavior).

The second avenue involves the use of knowledge (or the imposition of restraints) on the possible preferences of players.
This avenue often goes under the description of VCG redistribution, and there has been significant discussion about this particular avenue.
Originally the first to propose this scheme was Ruggiero Cavallo \cite{Cavallo:2006:ODM:1160633.1160790}, particularly in the context of allocating a single physical object exclusively to one party.
this game `All-Or-Nothing' games (AON) --- where any party's not recieving the object has known utility of zero --- has a better-than-VCG allocation mechanism.
Cavallo, discussed this allocation mechanism and then consideres the associations and implications for the potential design of other allocation mechanisms where information (or constraints) are known about the players true preferences.

The design of redistribution systems has since seen some more development, from redistribution systems in the context of other situations and games.
But, it is generally known that designing optimal (non-linear) redistribution systems is a hard task, and even neural networks have been employed to construct such systems \cite{DBLP:conf/atal/ManishaJG18}.

However it is known that these systems will (by construction) almost always produce some budget surplus.

A tertiary avenue to dealing with the problem is to throw away the pareto-optimality of outcome selection.
Probably one of the first people to think of this process way Boi Faltings \cite{10.1007/978-3-642-25510-6_14}
Who proceeds about the process of designing a non-pareto optimal VCG mechanism by splitting the population into two groups, where the VCG outcome from the first group is selected irrespective of the preferencs in the second group.
and where the second group recieves the budget surplus from the VCG mechanism applied to the first group.
This rather genius mechanism is the subject of a patent in the US (CITE), and constitutes a budget balanced VCG-type mechanism.
which can be made a little bit more baysean regular by randomy selecting the `sink', and splitting the budget surplus between the parties evenly without knowledge of who will be selected.\cite{10.1007/978-3-642-25510-6_14}

particularly this method selecting a non-pareto optimal outcome has been the subject of investigation, and the process is proven to nessisarily need a sink.
and that there are different ways to select an appropriate sink randomly \cite{NATH2019673}.

What is particularly interesting is that various VCG type mechanisms can potentially be scaled up, leading to `effectively' the impossible combination \cite{NATH2019673}.

There are several objections (and unanswered questions) to VCG as applied to electricity networks and more generally, and reasons why it has been seldom implemented in practice.\cite{journals/ior/Rothkopf07}\cite{Ausubel2006}
Though it has been proposed (and presumably implemented) in the context of cooperative multi-agent reinforcing (CITE-NASA)

Particularly it is not very obvious that VCG type payments are nessisarily economically reasonable payments between competitive parties, but much more payments between parties with incentives that are made to cooperate.

And although incentive compatability is a noble objective in mechanism design, it is still subject to strategic manipulation, particularly in the context of the forming of coalitions.

Coalition strategy proofness, has been proven to be quite generally a difficult concept to design, and in some cases has categorically proven to be impossible \cite{10.2307/2297048} without further elements, such as private information transfer and uncertainty.
Although there has been some effort in designing and analysing the occurance of coalition proof mechanisms, these remain difficult.

One of the considerations of using VCG is how it is to be constructed as a mechanism in the context of an electricity system.
and different people have published different ways to instigate such a system.
fundamentally, it involves the question of what the network should be considered to be in the absense of a particular player.
The solving of optimal utility is a classical OPF problem, and is it to be the case that the system would have to be solved to OPF for each of $n$ players?
This is a disadvantage of LMP, but not nearly as much as a disadvantage over Shapley Mechanisms.

If we discount the benefit of incentive compatability, then the fundamental question remains: how much \textit{should} (above other considerations) electrical participants be credited/debited according to their immediate influence apon others relative to their hypothetical absense.

In the following sections \ref{} we will compare the allocations of power/money in randomly generated networks under VCG against other schemes.


\subsection{Bargaining and Game Theory}

One component of analysis that is missing from VCG is the consideration between the outcomes that the players value and the actions which they \textit{dont} enact which then leads to thoes outcomes - and instead there is only considered the sum-utility of utility-maximising outcomes with and/or without the participation of particular players.

While this schema leads to coherent outcomes that are incentive compatible, it might also be seen to be a shortcomming as it fails to account for the divergence of possible actions (including negative ones) for the players and the effect that these would have on the group.

One of the most historic classes of solution concepts which involve an allocation of utility which involves the consideration of all the distinct actions for the players are the bargaining solutions.
particularly Nash bargaining with endogenous disagreement outcome.

\subsubsection{Nash bargaining with exogenous disagreement point}\label{sec:nash_bargaining_exogenous}

A bargaining solution concept applies in a situation where there are a number of parties (or agents) and a space of possible agreements which those agents can reach and value differently between themselves.
A bargaining solution concept identifies an outcome which the agents `will' (or `should') agree upon.
Perhaps the most famous bargaining solution concept is called the Nash-bargaining solution concept.

Nash bargaining was introduced \cite{nash1} as an axiomatic approach to predict the result of individuals who are bargaining over potential outcomes.
It is defined over a convex compact set of potential outcomes $F$ (which might coincide with power-flows and fiscal payments on an electricity network etc.) 
where each of the players $P=\{p_1,p_2,\dots\}$ value the outcomes differently with utilities $u_{p\in P}(f)$ for $f\in F$.
Additionally there is a privileged outcome called the `disagreement' outcome $d$ which represents the event of the negotiation between the players breaking down.

Nash identified that in this case there is a unique solution satisfying some very intuitive axioms:
\begin{itemize}
\item \textit{Invariant to affine transformations}: that the solution should not change if the utilities of either players are scaled (by some positive factor) or offset, ie that they are invariant under the set of affine transformations that might also represent their relative preferences.
\item \textit{Pareto optimality}: That the solution will not be inferior to any other point with respect to the preferences of all players.
\item \textit{Independence of irrelevant alternatives} (IIA): If any subset of potential outcomes does not feature the solution point then it could be removed without affecting the solution.
\item \textit{Symmetry}: The solution is invariant with regards to the ordering of the players.
\end{itemize}
This solution maximizes the product of utilities above the utility of the disagreement point:\cite{book1}
\begin{equation}\label{nash-product}\text{nash}(F,d) = \argmax_{(f\ge d)\in F}\prod_{p\in P}(u_p(f)-u_p(d))\end{equation}
In this way the Nash-bargaining-solution can be seen as a simple solution concept, whereby the participants report their valuations over potential outcomes, 
and a Pareto-optimal outcome is determined which maximizes the product of those utilities above the disagreement outcome.

In many cases of physical bargaining (which might involve alternating offers etc.) the `disagreement outcome' is often naturally dictated by the context of the bargaining process - 
such as the event of quitting in the context of a wage-negotiation or of walking-away from a potential sale
- It can be seen as the point of `threat' from which the bargaining process occurs, and which any player can unilatterally implement.\cite{nash2}

There has been much work since Nash published his famous paper (\cite{nash1}) investigating other and/or similar solution concepts, and these bargaining solutions (such as \cite{smorodinsky,tempered,tale1,anbarci2002comparing}) often relate to different axioms (most often rejecting axiom IIA) and privilage different points in the bargaining process.

One objection to the Nash bargaining solution is that it may not be considered natural or a reliable description of real-world bargaining.
Although there do exist some evolutionary models suggesting that in some social dynamics Nash bargaining might naturally emerge \cite{articlechoakihiko}, there does exists discussion and experimental work finding that real behavior between humans exhibits some ambiguity \cite{KROLL2014261}, even in the case when the disagreement point is naturally given by the setting.

However in other cases (such as in an electricity network) a singular disagreement outcome is not very clearly given by the context.
And so for a Nash bargaining solution concept to be applied then a disagreement outcome must be chosen from the set of possible outcomes $F$.
Which leads to the question of how we sould do this?

\subsubsection{Nash bargaining with endogenous disagreement point}

In John Nash's paper ``\textit{Two-person cooperative games}"\cite{nash2}, He explicitly addresses the consideration of the agents choosing a disagreement point between themselves in a prior stage in the bargaining process.

Particularly he considers a game specifically between two players, who reach a cooperative outcome in a series of stages of negotiations.
He considers that each of the players has a space of mixed strategies $S_i$ in a normal form game, and for each possible pair of mixed strategies that the players might execute, each recieves an immediate payoff $p_1(s_1,s_2)$ and $p_2(s_1,s_2)$ respectively ($s_1\in S_1$, $s_2\in S_2$).
He also considers that there is a set $B$ of possible payoffs for the players if they cooperate, which may be bigger than the set of payoffs in the normal form game.\\
$\text{ie.}\quad \forall s_1\in S_1,s_2\in S_2 \quad (p_1(s_1,s_2), p_2(s_1,s_2)) \in B$

Nash then considers a specific negotiation process:
\begin{enumerate}
\item Each player $i$ chooses a mixed strategy $t_i$ which he will be forced to use if the two cannot come to an agreement.
\item The players inform each other of their threats.
\item Each player $i$ decides upon his demand $d_i$, which is a point on his utility scale for which he/she will not accept any agreement which yeilds at less than the utility $d_i$ to him/her.
\item If there is a point $(u_1,u_2)$ in B such that $u_1 > d_1$, and $u_2 > d_2$, then the pay-off to each player $i$ is $d_i$. Otherwise, the pay-off to each player $i$ is $p_i(t_l, t_2)$.
\end{enumerate}

This process encodes a process that includes two choices for the players, first, they must choose a `threat' strategy $t_i$ which they will be forced to execute if they cannot reach further agreement, and secondly they need to choose a `demand' $d_i$ of the utility which they would like to recieve from the negotiation.
If it so happens that is possible for the players to have their demands muturally met then they recieve the utility associated with their demand.

Nash identifies that a natural choice of compatable demands in the second part of the game occurs at the maximising of the Nash product (Equation \ref{nash-product}) above a disagreement point determined by the execution of threat strategies (as illucidated in the previous section \ref{sec:nash_bargaining_exogenous})
Nash then identifies then that in light of this result for the second part of the game there exists a unique set of optimal choice of threats $t_i$ for the two players in the first part of the game; which is a Nash equilibrium of them with respect to the subsequent maximisation of the Nash product.

Nash also identifies this result via axioms:
\begin{enumerate}
\item For each game $(S_1,S_2,B)$ there is a unique solution $(v_1,v_2) \in B$
\item If $(u_1,u_2)$ is in $B$ and $u_1\ge v_1$ and $u_2\ge v_2$ then $(u_1,u_2)=(v_1,v_2)$
\item That order preserving linear transformation of utilitie do not change the solution. ie. for games with all utilities scaled (ie $u_1' = a_1u_1+b_1, u_2' = a_2u_2+b_2$ for $a_1,a_2\ge 0$) result in solution $(v_1',v_2')$ where $v_1'=a_1v_1+b_1$ and $v_2'=a_2v_2+b_2$.
\item The solution does not depend on which player is player `one', ie. all functions are symmetrical
\item If points from $B$ are removed except $(v_1,v_2)$ and the points $(p_1(s_1,s_2), p_2(s_1,s_2))$ for all strategies $s_1\in S_1,s_2\in S_2$ then the new game yeilds the same solution.
\item A restriction of strategies for a player cannot increase his/her resulting payoffs, ie. for $S_1'\subset S_1$ then $v_1(S_1',S_2,B)\le v_1(S_1,S_2,B)$
\item There exists single (unmixed) strategies such that player one's value wont increase, ie. there exists $s_1,s_2$ such that $v_1(s_1,s_2,B)\le v_1(S_1,S_2,B)$
\end{enumerate}

These axioms very similar to, but perhaps a little less obvious than Nash's game with exogenous disagreement point (as given in the previous subsection \ref{sec:nash_bargaining_exogenous}).

In anycase, this Nash bargaining solution is one example of a solution concept that explicitly considers strategies that dont just belong to social optima (such as 'threat' strategies) and how these might bear on the result of cooperative negotiations.
It is also quite evident that VCG mechanisms do not involve the consideration of these strategies.

This leads to the question of whether or not the consideration of `threat' strategies should (or would) play a role in the division of resources - such as in an electricity system.
Particularly it is identified by Nash that the role of threats in negotiations depends on a dynamic about their ability to be enforced.

\begin{displayquote}
A common device in negotiation is the threat ... If one considers the process of making a threat, one sees that its elements are as follows: A threatens B by convincing B that if B does not act in compliance with A's demands, then A will follow a certain policy T. Supposing A and B to be rational beings, it is essential for the success of the threat that A be compelled to carry out his threat T if B fails to comply. Otherwise it will have little meaning. For, in general, to execute the threat will not be something A would want to do, just of itself.
(\cite{nash2})
\end{displayquote}

In this light it is interesting to consider the role of threats in real-world cooperative negotiations. However, although Nash's bargaining solutions were first, there have since been developed alternative bargaining solution concepts that do not involve `threat' dynamics. \cite{bozbay}
It is also good to note that the endogenous disagreement point is unique only in the two player context, for three or more players there can exist multiple Nash equilibrium in the selection of disagreement point.\cite{10.2307/43616981}

It is worth noting that Nash's solution concept has a very simple form in the case of two-player games where utility is transferable (TU) \cite{value2,shap_lectures,value1}, equivalent to the sometimes called the `coco-value' in the case of complete information \cite{kalai1,Kalai2010}.
We present this simple form in the context of an example game from Neyman and Kohlberg's papers (\cite{value2,value1}).
Consider the strategic game between two players (a row player and column player):
\begin{equation}\label{eq:example_game1} \begin{bmatrix}2,1 & -1,-2\\ -2,-1 & 1,2\end{bmatrix} \end{equation}
And consider that these players can share utility between themselves (ie. a TU game). In this context the Nash bargaining solution is found as follows:
we consider that the maximum sum of utility which is achievable between the players $s=3$.
We then form the zero-sum game of the differences in player payoffs
$$ \begin{bmatrix}1 & 1\\ -1 & -1\end{bmatrix} $$
Where we find that the minimax value of this game is $d=1$ Which indicates that the row player has a greater threat power.
The Nash bargaining solution between the two players gives them utility as $(\frac{1}{2}s+\frac{1}{2}d,\frac{1}{2}s-\frac{1}{2}d) = (2,1)$
The way in which this is seen to be the nash bargaining solution for this game can be gleamed by inspection from Figure \ref{fig:graph1_utilities}.
Where the red lines corresponding to possible transfers of utility, show that the choice of disagreement point only matters insofar as it maximises the payoff advantage of one player over another.
this payoff advantage is then an offset along the diagonal of pareto frontier.

Particularly the measure minimax payoff advantage has been considered as a measure of bargaining power between two players, and has been a usefull component in other solution concepts.
Which in-turn also has a well-studied extension to many players.\cite{values1,values2,values3}
However, in the next section \ref{sec:cooperative_game_theory_part}, we must introduce considerations of manty players in the context of cooperative game theory.

\definecolor{wwwwww}{rgb}{0.4,0.4,0.4}
\definecolor{ccqqqq}{rgb}{0.8,0,0}
\definecolor{qqqqff}{rgb}{0,0,1}
\definecolor{wqwqwq}{rgb}{0.3764705882352941,0.3764705882352941,0.3764705882352941}
\definecolor{cqcqcq}{rgb}{0.7529411764705882,0.7529411764705882,0.7529411764705882}
\definecolor{strategy}{rgb}{0.7,0.7,0.9}

\begin{figure}[tb]
\centering
\begin{tikzpicture}[line cap=round,line join=round,>=triangle 45,x=1cm,y=1cm]
%strategy polygon
\clip(-3,-3) rectangle (4,4);
\draw[fill, opacity=1, color=strategy] (2,1) -- (1,2) -- (-2,-1) -- (-1,-2);
%grid and axes
\draw [color=cqcqcq,dotted, xstep=0.5cm,ystep=0.5cm] (-3,-3) grid (4,4);
\draw[->,color=wqwqwq] (-3,0) -- (4,0);
\draw[->,color=wqwqwq] (0,-3) -- (0,4);
%grid numbers
\foreach \x in {-3,-2.5,-2,-1.5,-1,-0.5,0.5,1,1.5,2,2.5,3,3.5,4}
\draw[shift={(\x,0)},color=wqwqwq] (0pt,2pt) -- (0pt,-2pt) node[below] {\scalebox{0.35}{$\x$}};
\foreach \y in {-3,-2.5,-2,-1.5,-1,-0.5,0.5,1,1.5,2,2.5,3,3.5,4}
\draw[shift={(0,\y)},color=wqwqwq] (2pt,0pt) -- (-2pt,0pt) node[left] {\scalebox{0.35}{$\y$}};
\draw[color=wqwqwq] (-2pt,-3pt) node[right] {\scalebox{0.35}{$0$}};
%red lines
\draw [line width=1.0pt,color=ccqqqq] (-1,4) -- node[above,sloped,pos=0.8]{\tiny Pareto Frontier} (4,-1);
\draw [line width=0.6pt,color=ccqqqq] (-3,0) -- (0,-3);
%grey lines
\draw [dash pattern=on 1pt off 1pt,color=wwwwww] (-2,-1) -- (3,4);
%\draw [dash pattern=on 1pt off 1pt,color=wwwwww] (1,-5) -- (6,0);
%hyperbola
\draw[samples=50, domain=-0.5:4,smooth,color=wwwwww,line width=0.5pt,dash pattern=on1pt off 1pt] 
plot ({\x},{(9/(\x+2))-1});

\begin{tiny}
%labels
%\draw [color=black] (1.5,-5) node {maxmin};
%\draw [color=black] (3.572727273,-1.272727273) node {coco};
%\draw [color=black] (4.4,-2) node {a-coco};
%\draw [color=qqqqff] (1.5,1) node {maxmax};
%\draw [color=black] (0.5,-4.4958677686) node {minimax};
\draw [color=wqwqwq] (0.4,1.7) node [label={[align=left]Player1\\utility}]{};
\draw [color=wqwqwq] (1.9,0.15) node {Player2 utility};
%points
\draw [fill=qqqqff] (2,1) circle (1.7pt);
\draw [fill=qqqqff] (1,2) circle (1.7pt);
\draw [fill=black] (-2,-1) circle (1.7pt);
\draw [fill=qqqqff] (-1,-2) circle (1.7pt);
%\draw [fill=wwwwww] (1,-5) ++(-2.5pt,0 pt) -- ++(2.5pt,2.5pt)--++(2.5pt,-2.5pt)--++(-2.5pt,-2.5pt)--++(-2.5pt,2.5pt);
%\draw [fill=wwwwww] (0.0495867769,-4.4958677686) ++(-2.5pt,0 pt) -- ++(2.5pt,2.5pt)--++(2.5pt,-2.5pt)--++(-2.5pt,-2.5pt)--++(-2.5pt,2.5pt);
%\draw [color=black,line width=0.8pt] (3.272727273,-1.272727273)-- ++(-3pt,0 pt) -- ++(6pt,0 pt) ++(-3pt,-3pt) -- ++(0 pt,6pt);
%\draw [color=black,line width=0.8pt] (4,-2)-- ++(-3pt,0 pt) -- ++(6pt,0 pt) ++(-3pt,-3pt) -- ++(0 pt,6pt);
\end{tiny}

\end{tikzpicture}
\caption[Utility diagram for example game.]{The potential outcomes for the TU example game (Equation \ref{eq:example_game1}). Red lines show all potential outcomes of pure strategies with TU. Blue points show non-TU pure strategy outcomes. The blue polygon shows space of outcomes for non-TU mixed strategies, The outcome that corresponds to the minimax strategy of the zero-sum component is shown in black. The Nash Bargaining value is shown on the pareto frontier as the feasible outcome that maximises the product of utilities above the minimax disagreement-point, the hyperbola of this maximum product is shown.}
\label{fig:graph1_utilities}
\end{figure}



\subsection{Cooperative Game Theory}\label{sec:cooperative_game_theory_part}

The idea that people (collectively) should be afforded atleast what they could achieve by themself is most directly articulated by the \textit{Core} of cooperative game theory.

In this section we will detail only some of the parts of the theory of cooperative games which bear relevance and apon the quetions of distribution that we raise.

The basic elements of a classic cooperative game is that there is a set of players or individuals $N=\{1,2,\dots n\}$ and a function $v: S\subseteq N \rightarrow \mathbb{R}$ with $v(\emptyset)=0$ called the \textit{characteristic function}.
The characteristic function identifies in some sense the `worth' of any group of players (a `coalition') which might be interpreted in terms of utility or monetary value.
One aim in cooperative game theory is to evaluate schemes (or `solution concepts') which split the wealth achieved if everybody cooperated (that is $v(N)$) between all the players.

However this kind of formulation does beg the question how the characteristic function should be determined.
%, and they encode information that there is a set of players and a notion of how much each subset of players `is worth'.

\begin{displayquote}
The idea is to capture in a single numerical index the potential \underline{worth} of each coalition of players.
...

With the characteristic function in hand, all questions of tactics, information, physical transactions, etc., are left behind. The characteristic function is primarily a device for dividing the difficulties -- for eliminating as many distractions as possible in preparation for the confrontation with the indeterminancy of what we have called the ``n-person problem''. Engrossed with this problem, many authors writing after von Neumann and Morgenstern have begun by basing their solution concepts on the characteristic function above, with no initial concern for the concrete rules of the game, in strategic or extensive form.

Unfortunately, not all games admit a clean separation between strategic and coalitional questions, and for those that do not the characteristic function approach must be modified or abandoned.\cite{ShapleySchubikCharacteristicFunction}
\end{displayquote}

However some games do admit a clean separation between strategic and coalitional questions.
For instance, if there is a situation where the Characteristic function identifies the amount of utility/money/etc that members of a coalition could and unambiguously would, achieve by working by themself.

In this context, If the most amount of money that can be achieved is gained by everbody working together then the idea that this should be executed and that each member or possible group should be given more than they could feasibily get by themselves is a condition best described by the core:

\subsubsection{the Core}

Particularly, the core is an example solution concept for cooperative games:

$$ C(v) = \left\{x\in\mathbb{R}^n : \sum_{i\in N}x_i=v(N); \sum_{i\in S}x_i \ge v(S), \forall S\in N \right\}$$

The core is the set of possible allocations such that the sum of them equals what can be achieved by everybody working together (the worth of the `grand coalition' - $v(N)$) and such that for any group of individuals, the sum allocated to thoes individuals is greater than what they could achieve by working by themself.

The allocations that belong to the Core have a sense of being stable - in that no coalition would have an incentive to split from the cooperative engagement to get a better payoff. One major drawback about the core is that it does not determine a unique outcome, but potentially a range of outcomes or perhaps none at all.

Indeed the Core may be empty, and there are modifications to the Core concept which remedy this problem.
When no Core solutions exist, then straightforwardly no solution can posess the same kind of stability, however there is perhaps allocations that minimise this shortcomming.
particularly the \textit{least-core} solution concept.

The least-core solution concept is a particular instance of the \textit{strong $\epsilon$ core} which is defined as follows:
$$ C_\epsilon(v) = \left\{x\in\mathbb{R}^n : \sum_{i\in N}x_i=v(N); \sum_{i\in S}x_i \ge v(S)-\epsilon, \forall S\in N \right\}$$
The strong $\epsilon$ core is the set of allocations in which each coalition is allocated atleast their value minus some constant $\epsilon$.
In this way some coalitions might be shortchanged, but only by atmost a constant factor $\epsilon$.
The strong $\epsilon$ core can be defined for positive and negative $\epsilon$ values, it will certainly be non-empty for very large and positive $\epsilon$ values and certainly be empty for very large and negative $\epsilon$ values.
In this way we can consider the limiting case between these two, the smallest value of $\epsilon$ in which the strong $\epsilon$ core is non-empty - and this is the least-core.\cite{doi:10.1287/moor.4.4.303}
The least-core is therefore always non-empty and may even identify a singular solution. point; that can be said to minimum `dissatisfaction' between the groups.

The core is probably an intuitive solution concept in the context where the characteristic function identifies the `worth' of individuals and groups `by-themself' and the dynamics are driven by this isolation mechanic.
However in other cases the `worth' identified by the characteristic function is in the context of cooperation with the others, or perhaps otherwise.
And in this context the Core is not the only solution concept worth considering.

\subsubsection{The Shapley Value}

The \textit{Shapley value} is another specific and well known solution concept in cooperative game theory.
Particularly the Shapley value allocates to each individual the average contribution he/she would add across the possible coalitions to which he/she could join.

So particularly, if for any coalition $S$ which does not include player $i$, $i$'s marginal contribution is $v(S\cup\{i\}) - v(S)$. If we average such contributions for coalitions of size $k$:
\begin{equation}\label{eq:shapley_value2}
\hat{v}_{i,k} = \frac{1}{\binom{n-1}{k}}\sum_{S\subset N\setminus \{ i\} , |S|=k} %\frac{(n-|S|-1)!\,|S|!}{(n-1)!}
(v'(S\cup\{i\})-v'(S))
\end{equation}
Then we have the average marginal contribution of player $i$ to coalitions of size $k$, and if we average this over coalitions of different size, we get the Shapley value:
\begin{equation}\label{shap2} \varphi_i(\langle N,v\rangle) = \frac{1}{n}\sum_{k=0}^{n-1}\hat{v}_{i,k} \end{equation}
The Shapley value is an averaging over a players marginal contributions, which is obviously a unique allocation for any cooperative game.

The Shapley value for a player can also be formulated as being the expected marginal contribution across all join ordering processes.
So for instance, if we let $\pi(N)$ denote the set of all ordered permutations of the player set $N$ and if we denote $Pre^i(O)$ as the set of predecessors of player $i$'s addition in that ordering $O\in \pi(N)$. Then the shapley value can be expressed as the average marginal contribution across orderings, \cite{weber_1988}:
\begin{equation}
    \varphi_i(\langle N,v\rangle) = \frac{1}{n!}\sum_{O\in\pi(N)}v(Pre^i(O)\cup\{i\})-v(Pre^i(O))
\end{equation}

The Shapley value has perhaps some moral intuition behind it - rewarding each person in proportion to what they would add across any ordering that the coalition could form.
But more than that, the Shapley value has been derived from different sets of quite intuitive axioms.
For instance:

\begin{itemize}
\item	\textbf{Efficiency}: That the total dividend is broken up, $\sum_i\varphi(\langle N,v\rangle)_i = v(N)$
\item	\textbf{Symmetry}: If two players $i$ and $j$ are substitutes and contribute the same to all coalitions, such that if $v(S\cup i)=v(S\cup j)~~\forall S\subseteq N\setminus\{i,j\}$, then $\varphi(\langle N,v\rangle)_i = \varphi(\langle N,v\rangle)_j$
\item	\textbf{Dummy Player}: If a player $i$ is a dummy player if the amount that $i$ contributes to any coalition is the amount that $i$ is able to achieve alone (i.e.\ $v(S\cup \{i\})-v(S)=v(\{i\})~~\forall S\subseteq N\setminus\{i\}$) then $\varphi(\langle N,v\rangle)_i=v(\{i\})$
\item	\textbf{Additivity}: That for any two games, the imputation for the two together is the sum of the imputations in each, for any $v_1$ and $v_2$, $\varphi(\langle N,v_1+v_2\rangle)=\varphi(\langle N,v_1 \rangle) + \varphi(\langle N,v_2\rangle)$
\end{itemize}

These axioms might seem pretty reasonable and lead uniquely to the Shapley value allocation, and these are not the only set of axioms sufficient to derive the shapley value either.

This raises the question of when the Shapley value is in the Core? - and therefore has that particular stability that would disincentivise any subset from leaving.
One example case in which the Shapley Value is always in the core is in the context of Convex cooperative games:
A cooperative game is \textit{convex} iff:
\begin{equation}
    \forall S,T\subset N \quad v(S\cup T) \ge v(S)+v(T)-v(S\cap T)
\end{equation}

\subsubsection{Applications to Electricity Systems}

Shapley value concepts are increasingly being considered as a mechanism for pricing in the various facets of electricity system operation.

Such as: demand response participation \cite{DBLP:journals/tsg/OBrienGR15,electronics8010048,WANG201972}, compensation for the aggregation of power \cite{Perez-Diaz:2018:CEV:3237383.3237484,6520960}, allocating transmission costs and losses \cite{ip-gtd_20020005,SHARMA201733}, allocating profits for retailers and \cite{ACUNA2018161,WANG201972}, allocating surplus and savings in microgrids \cite{WU2017384} and allocating costs in distribution and embedded networks \cite{archie_paper1,8226810,10.1007/978-3-642-40776-5_19,6840296,DBLP:journals/corr/abs-1903-10965,AzuatalamCV_PowerTech2019}.


%Shapley value concepts are increasingly being considered as mechanisms for pricing and cost allocation in various facets of electricity system operation.
%Example include: demand response participation \cite{DBLP:journals/tsg/OBrienGR15,electronics8010048,WANG201972}; 
%compensation for the aggregation of power \cite{Perez-Diaz:2018:CEV:3237383.3237484,6520960};
%allocating transmission costs and losses \cite{ip-gtd_20020005,SHARMA201733}; allocating profits for retailers and \cite{ACUNA2018161,WANG201972}; 
%allocating surplus and savings in microgrids \cite{WU2017384} and; 
%allocating costs in distribution and embedded networks \cite{archie_paper1,8226810,10.1007/978-3-642-40776-5_19,6840296,DBLP:journals/corr/abs-1903-10965,AzuatalamCV_PowerTech2019}.



In each of these cases, the primary difference is the context of application and the specific way in which the characteristic function is constructed.
In any advocacy of the shapley value for an application, is tacitly advocacy of to each individual by the marginal contribution that they could add in a coalition formation process.
Which may or may-not coincide with the Core and its coalitional stability property.
in Chapter \ref{} we compare -an- application of the Shapley value applied to electricity systems against other allocation methods.

There exist other solution concepts in the context of cooperative game theory, such as the Kernel and Neucleolus. and we have only touched the surface of cooperative game theory only enough for it to be relevant for our purposes.
The interested reader is encouraged to read more from sources \ref{} and \ref{} and \ref{}.

\subsection{Economic Perspectives}

In this way what is considered exploitation and unfair trade, in defined in contrast to the value that is fetched in normative market circumstance.
the question then becomes how to formulate this normative market circumstance.

Various Economic models and market simulations can be done to address such questions.
however one of the most notable economoic paradigms is that of economoic marginalism.

The theory of Value, has a long history with a notable waystation being Marxist labor theory of value. since then.....

\subsection{Summary}
Summary what you discussed in this chapter, and mention the story in next
chapter. Readers should roughly understand what your thesis takes about by only reading
words at the beginning and the end (Summary) of each chapter.






\section{Discussion}
\label{sec:discussion}

This section involves a multi-part discussion of the features of the derived results and their numerical performance.
particularly we discuss:
\begin{itemize}
\item	in subsection \ref{subsection:discussion_EBB} we discuss the nature and effectiveness of our derived EBB from section \ref{section:new_EBB}.
\item	in subsection \ref{subsection:main_discussion} we discuss the performance of our new SEBM method, in the context of synthetic data
\item	in subsection \ref{sec:multi} we give indication of future work regarding the extention of SEBB to multidimensional data.
\end{itemize}



\subsection{The effectiveness of our new EBB}\label{subsection:discussion_EBB}

By being able to numerically evaluate our EBB, we were able to compare the strength of our results against existing concentration bounds, particularly our EBB is compared to Maurer and Pontil's EBB and, Bennett's inequality with perfect variance information.

We compared our EBB directly with \cite{Maurer50empiricalbernstein}'s EBB, 
given by:
\begin{equation}\label{maurersbound} \p\left(\mu-\hat{\mu}>\sqrt{\frac{2\hat{\sigma}^2\log(2/y)}{n}}+\frac{7D\log(2/y)}{3(n-1)}\right)<y. \end{equation}
We felt that it would be fair to compare our EBB to Maurer and Pontil's EBB if they had applied Popoviciu's inequality as a domain restriction and carried it through their derivation, as we did to our own EBB. 
Specifically, this is the domain where:
\[ \frac{1}{2}>\frac{\sqrt{\hat{\sigma}^2}}{D}+\sqrt{\frac{2\log(2/y)}{n-1}} \]
We plotted the improvement our EBB offers in this domain, as shown in Figure \ref{biggraph3}. 
In this plot, a probability 0.5 bound is shown to shrink by approximately one third.
But that generally, we observed that our refinement of Maurer and Pontil's EBB was expectedly uniformly tighter across a large range of values.


\input{figs/ebb_strength.tex}


Secondly, a comparison is made of the further improvement in confidence over our EBB that might be achieved with perfect information about the variance; specifically that, Bennett's inequality is used assuming $\hat{\sigma}^2=\sigma^2$. 
This improvement is plotted in Figure \ref{biggraph4}, which shows that when the variance is small, uncertainty about the variance is the most detrimental to an EBB, such as ours.
However, in general, going from our EBB to perfect variance information shrinks the bounds by about another third.

In this way (although the results are loose) we can witness that our EBB provides approximately a half-way mark from existing state-of-the-art EBBs to an impossible ideal of having perfect variance information.

The purpose of developing a novel EBB was to see if it could be used to improve the selection of samples in the context of stratified sampling (particularly of the Shapley Value).
The performance of this new EBB offers (against others) in the context of choosing samples for stratified Stratified Sampling is considered in Section \ref{section:statistics_results}.







\subsection{Discussion of stratified sampling results}\label{subsection:main_discussion}


It is evident that for any probability bound for the error of our stratified sampling mean estimate, it is possible to choose additional samples from strata to minimise the expression.
And it is expected that the better and more tight the bound, the more likely it will be the case that iteratively choosing samples to minimise the bound will infact produce better estimate of the population mean in practice.
One of the best ways of testing this hypothesis is with actual data, where divergent sets of synthetic data can be generated (with their mean calculated exactly) and the different methods of sampling tested to see how well they estimate the known means.
And this is the approach that is taken in the next section, where we compare the accuracy attained via process of minimising the different probability bounds developed in this chapter.












In this section we give considerations to the numerical results of this chapter.
In general, from the results across Figures~\ref{Table1},\ref{Table111} and \ref{biggraph3} and Table \ref{Table2}, the main observation is that most of the techniques performed well and similar to Neyman sampling, and that our sampling technique, SEBM (or SEBM-W) and SECM performed competitively to Neyman sampling (\textsc{Ney} or \textsc{Ney-W}) despite not having access to knowledge of strata variances.
It is also observed that Neyman sampling was ultimately the most accurate, for reasons that were hinted in section \ref{sec:neyman_sampling}.
Particularly that if sufficient samples have been taken then the sample means of the strata will tend to approximately be Gaussian distributed by the Central Limit Theorem.
In this context the strata means have a distribution that is entirely characterised by their mean and variance, and hence so too is the population mean estimate.
In this way the variance of the sampled population mean is the only parameter determining its error, and minimising it directly translates into improved accuracy.

%One of the most remarkable inferences from the data is just how very readily Central Limit Theorem dynamics emerges, from Figure \ref{fig:central_limit_theorem} we can see that the sample error of uniformly distributed data converges almost perfectly to a gaussian distribution even in just 4 samples.


This dynamic speaks strongly to the efficiency of Neyman sampling, and indeed our method SEBM* performs worse as it extends from minimising only a simplification of Bennett's inequality - this is most evident in figure \ref{biggraph3}.\footnote{we would expect that a method consisting of minimising Bennett's inequality proper, would yield extremely similar results to Neyman sampling}.

The relative inefficiency of the SECM method is interesting, particularly as it sought to minimise Chebyshev's inequality for the stratified sampling, and under perfect variance information would be identical to Neyman sampling.
The implication in this context is that the inefficiency of utilising these methods primarily extended from uncertainty about the variances of the strata.

The Bernoulli-uniform data results (plotted in \ref{biggraph3}) were specifically designed to amplify the detriment in stratified sampling that uncertainty about the variances would yeild.
And that the more infrequent the Bernoulli outlier, the more likely that the methods without variance information would over-sample the bernoulli stratum - which they did.
It is interesting that the SEBM* method also did this to some extent, although it is not particularly clear exactly why.


From between Figures~\ref{Table1} and \ref{Table111} we observe that sampling without replacement always performs better than sampling with replacement for the same method, and this improvement is magnified as the number of samples grows large relative to the size of the population. 
At the same time, simple \textsc{Random} sampling almost always performs worst, because it fails to take advantage of any variance information, and \textsc{Simple} sampling performs even worse as it fails to take into account data stratification, these results are as expected.
Therefore from the Figures ~\ref{Table1} and \ref{Table111} we see that the primary increase in performance comes from employing stratified sampling over simple sampling, sampling without replacement over sampling with replacement, and then using some method that is more intelligent than randomly selecting samples (\textsc{Random} method) and preferably using stratum variance information to get close to the ideal of Neyman sampling.

Aside from comparing the different performances of these bounds as a target for minimisation by selective sampling, it also pays to consider them on their own - simply as bounds on the stratified mean error.
Particularly we can see a range of different strengths of the bounds in Figure \ref{fig:bounds_widths}.

In Figure \ref{fig:bounds_widths} we have plotted the bound widths of the various probability bounds of this paper in the context of the Beta-distributed data we considered in section \ref{sec:beta_distributed_data} achieved after a sample budget $n=50N$ samples allocated using \textsc{Ney-W} method.
In this graph we considered the following bounds for the error:

\begin{itemize}
\item 
\textsc{Ney-B} The bound attained using knowledge of the variances of the strata using Chebyshev's inequality (Theorem \ref{thm:chebyshevs}) in conjunction with the additivity of variance rule (Equation \ref{eq:variance_decomposition_for_strata_mean})
\item 
\textsc{SEBB*} The bound of Theorem \ref{thm:1} with variance knowledge of the variances, also using sampling without replacement sharpening (Theorem \ref{martingale0}) where optimal.
\item 
\textsc{SEBB*-W} The bound of Theorem \ref{thm:1} with variance knowledge of the variances, not using sampling without replacement sharpening (Theorem \ref{martingale0}).
\item 
\textsc{SECB} The bound of Theorem \ref{thm:SECM_bound}, which utilises Chebyshev's inequality together with our probability bound on error deviation.
\item 
\textsc{SEBB} The bound of Theorem \ref{thm:SEBM_bound}, using sampling without replacement sharpening (Theorem \ref{martingale0}) where optimal.
\item 
\textsc{SEBB-W} The bound of Theorem \ref{thm:SEBM_bound}, not sampling without replacement sharpening (Theorem \ref{martingale0}).
\item 
\textsc{Hoeffding-B} The bound attained by Hoeffding's inequality (Theorem \ref{Hoeffdings_inequality_proper}) for the strata, unioned together (via Theorem \ref{triangle_theorem2}) to create a bound on the stratified sampling error.
\item 
\textsc{Audibert-B} The bound attained by Audibert et.al's EBB inequality (Theorem \ref{AudibertsEBB}) for the strata, unioned together (via Theorem \ref{triangle_theorem2}) to create a bound on the stratified sampling error.
\item 
\textsc{Maurer-B} The bound attained by Maurer and Pontil's EBB inequality (Theorem \ref{MandPsEBB}) for the strata, unioned together (via Theorem \ref{triangle_theorem2}) to create a bound on the stratified sampling error.
\end{itemize}

Particularly we see from Figure \ref{fig:bounds_widths} that tightest bounds are given by those methods which are rooted in perfect variance information, and the widest bounds are given by those methods which utilise probability unions to bind EBBs together (via Theorem \ref{triangle_theorem2}).
What is most notable is the dissimilarity between the widths of the bounds and their effectiveness as a target for sampling minimisation; as choosing samples to minimise a probability bound is sensitive to the shape of the bound not its magnitude.
Also comparing this Figure \ref{fig:bounds_widths}, with Figures \ref{Table1},\ref{Table111} we can see that the width of the bounds are much wider than the magnitudes of the error which are actually achieved; and this is quite expected, as analytic concentration inequalities function generally as conservative confidence intervals on the error of sampling.

%\input{figs/convolution_graph.tex}
\input{figs/widths_graph.tex}

%Next, note that the results of Figure~\ref{Table1} show that there is a mid-range of sample sizes where choosing a different method can even have a greater impact on sampling efficiency and rate of average error reduction than the difference between sampling with or without replacement.
%This is an important insight, as sampling real-world data (e.g. surveys, polling, destructive testing, etc) can be an expensive and slow process.
%Accordingly an appropriate method of choosing numbers of samples can lead to a material difference in cost for the same accuracy.
%There is also a slight decrease in the performance of SEBM* in comparison with \textsc{Ney} in the case of high number of samples and sampling without replacement, as illustrated in Figure~\ref{Table1}. 
%This indicates that the use of sub-optimal equation~\ref{approx1} in the derivation of Lemma~\ref{martingale0} might have some negative effect, by distorting the shape of the functions that the sampling processes then minimizes.

%If the data features very rare events, then SEBM and SEBM* seem to perform in a manner less than ideal.
%These condition are illustrated in Figure~\ref{biggraph3}, where the more rare the Bernoulli variable successes, the worse our methods perform in comparison with Neyman sampling (\textsc{Ney}).
%This shortcoming can be partly explained by noting that SEBM unnecessarily wastes samples on the Bernoulli stratum of rare events in the process of learning that the variance is almost zero, whereas \textsc{Ney} can avoid this because it has prior knowledge of the variances to begin with. 
%As such, this factor explains the difference between the performance of SEBM and SEBM* in the context of Figure~\ref{Table1} and also in Figure~\ref{biggraph3}.
%What is surprising is how small the difference in performance between SEBM and SEBM* is. 
%This indicates that as additional samples are taken, the original uncertainty about the strata variances have less and less effect upon the total numbers of samples that are eventually drawn from each of the strata.

%However, the performance difference between SEBM* and \textsc{Ney} in Figure~\ref{biggraph3} is not explained by this argument, as they use the same information.
%Instead, the reason for this difference in performance is found by considering the simplifying approximation of Equation \eqref{eq:part2} in the derivation of Lemma~\ref{expectation1}. 
%Specifically, \eqref{eq:part2} introduces a particular distortion into the shape of Equation~\eqref{big_equation} which our sampling seeks to minimize.
%Figure~\ref{fig:graph2} illustrates how the approximation \eqref{eq:part2} loosens the bound with respect to the variance. 
%Observe that when the variances are very small that Equation~\eqref{eq:part3} overly loosens the bounds, causing oversampling of strata with very small variances. 
%It appears that this factor is at play in the under-performance shown in Figure~\ref{biggraph3} and also the slight under-performance of our method in the Voting Game in Table~\ref{tab2}. 
%We note that there may be other corner-cases where our method also under-performs.

In considering the comparison of approaches to approximating the Shapley value, our sampling method shows improved performance on almost all accounts, as shown in Table~\ref{Table2}.
This was particularly the case in the context of large sample budgets, as our method (SEBM, with error $e^{SEBM}$) sampled without replacement, while the other methods sampled with replacement. 
However it would be remiss not to mention the computational overhead of iteratively minimising (one sample at a time) our inequality in the context of our simple example games. 
This overhead can be a significant drawback, however on more complicated games such as where the characteristic function is slower to calculate, any overhead associated with the sampling choice is expected to be much less relevant. 
We also note that our method's performance could potentially be further improved by selecting more refined $D_i$ values for our example games.

However we attribute our methods success in estimating the Shapley Value primarily to the design decisions used in the creation of those other methods.

%\input{figure-22.tex} 




One primary limitation of our method(s) is that it rests on assumption of known data widths $D_i$ (and in the case of sampling-without-replacement, also on strata sizes $N_i$), which may not be exactly known in practice.
One way to overcome this may be to use our method with a reliable overestimate these parameters (by expert opinion or otherwise). This approximation or estimation may itself open consideration of other probability bounds and/or sampling methods, however we have not investigated this line of inquiry. 

In practice, it might also be advisable to run our method with an underestimate of the data widths, as the sampling process is fundamentally sensitive the the shape of the inequality and not necessarily its magnitude or accuracy as a bound.\footnote{
Sourcecode for all the experiments in this paper are available at:\\ \href{https://github.com/Markopolo141/Stratified\_Empirical\_Bernstein\_Sampling}{https://github.com/Markopolo141/Stratified\_Empirical\_Bernstein\_Sampling
}}

% Our concentration inequality, Equation~\eqref{big_equation}, is derived by a combination of Chernoff bounds fused together with probability unions, so it is expected to give conservative confidence intervals on the error of the estimate in stratified random sampling, which may be useful outside of the context of sampling decisions.







\subsection{Future Work: applications of a Multidimensional Extension}\label{sec:multi}

Although we will not be evaluating this potential, it is notable that our SEBB can be extended to multidimensional data by a simple modification.
Specifically, instead of considering data that is single-valued, we consider data points that are vectors. 

Formally, for $n$ strata of finite data points which are all vectors of size $M$, let $n_i$ be the number of data points in the $i$th stratum.
Let the data in the $i$th stratum have a mean vector values $\mu_i$ (with $\mu_{i,j}$ for the $j$th component of the vector), which are value bounded within a finite width $D_{i,j}$, and have vector value variances $\sigma_{i,j}^2$.  
Given this, let $X_{i,1},X_{i,2},\dots,X_{i,n_i}$ (where $X_{i,k,j}$ is the $j$th component, of the $k$th vector from stratum $i$) be vector random variables corresponding to those data values randomly and sequentially drawn (with or without) replacement. 
Denote the average of the first $m_i$ of these random variables from the $i$th stratum by $\chi_{i,m_i}= \frac{1}{m_i}\sum_{k=1}^{m_i}X_{i,k}$ (with $\chi_{i,m_i,j}$ being the $j$th component of that vector average).
Let $\doublehat{\sigma}_{i,j}^2=\frac{i}{m_i-1}\sum_{k=1}^{m_i}(X_{i,k,j}-\chi_{i,m_i,j})^2$ be the unbiased sample variance of the first $m_i$ of these random variables in the $j$th component. 
As before, we assume weights $\tau_i$ for each stratum. \\
In this context we have the following theorem:

\begin{theorem}[Vector SEBM bound]
In the context above, then with $\Omega_{m_i}^{n_i},\Psi_{m_i}^{n_i}$ per Lemma~\ref{martingale1}:
%\begin{equation}\label{big_equation2}\p\left(\begin{matrix*}[l]\sum_{j=1}^M\left(\sum_{i=1}^n\tau_i(\chi_{i,m_i,j}-\mu_{i,j})\right)^2 \ge \\ \quad\quad \log(6/p)\sum_{j=1}^M\begin{pmatrix*}[l]\sum_{i=1}^n\frac{4}{17}\Omega_{m_i}^{n_i}D_{i,j}^2\tau_i^2 \\ +\begin{pmatrix*}[l]\sqrt{\log(3/p)\left(\max_i\tau_i^2{\Psi_{m_i}^{n_i}}^2D_{i,j}^2\right)} \\ +\sqrt{\begin{matrix*}[l]2\sum_{i=1}^n\tau_i^2\Psi_{m_i}^{n_i}(m_i-1)\doublehat{\sigma}_{i,j}^2/m_i \\ + \log(6n/p)\sum_i\tau_i^2D_{i,j}^2\Omega_{m_i}^{n_i}\Psi_{m_i}^{n_i} \\ +\log(3/p)\left(\max_i\tau_i^2{\Psi_{m_i}^{n_i}}^2D_{i,j}^2\right)\end{matrix*}} \end{pmatrix*}^2\end{pmatrix*}\end{matrix*} \right)\le Mp \end{equation}

\begin{equation}\label{big_equation2}\pr\left(\begin{matrix*}[l]\sum_{j=1}^M\left(\sum_{i=1}^n\tau_i(\chi_{i,m_i,j}-\mu_{i,j})\right)^2 \ge \\ \quad\quad \log(6/p)\sum_{j=1}^M\left(\alpha_{m_i,j}^{n_i} +\left(\sqrt{\beta_{m_i,j}^{n_i}} +\sqrt{\gamma_{m_i,j}^{n_i}}\right)^2\right)\end{matrix*} \right)\le Mp \end{equation}

where:

\begin{align*}
\alpha_{j}=&\sum_{i=1}^n\frac{4}{17}\Omega_{m_i}^{n_i}D_{i,j}^2\tau_i^2 \\
\beta_{j}=&\log(3/p)\left(\max_i\tau_i^2{\Psi_{m_i}^{n_i}}^2D_{i,j}^2\right) \\
\gamma_{j}=&2\sum_{i=1}^n\tau_i^2\Psi_{m_i}^{n_i}(m_i-1)\doublehat{\sigma}_{i,j}^2/m_i
+ \log(6n/p)\sum_i\tau_i^2D_{i,j}^2\Omega_{m_i}^{n_i}\Psi_{m_i}^{n_i}  \\
&\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad~~+\log(3/p)\left(\max_i\tau_i^2{\Psi_{m_i}^{n_i}}^2D_{i,j}^2\right)
\end{align*}

%$$
%\alpha_{m_i,j}^{n_i}
%=\sum_{i=1}^n\frac{4}{17}\Omega_{m_i}^{n_i}D_{i,j}^2\tau_i^2 
%$$
%$$
%\beta_{m_i,j}^{n_i}
%=\log(3/p)\left(\max_i\tau_i^2{\Psi_{m_i}^{n_i}}^2D_{i,j}^2\right) 
%$$
%and
%\begin{align*}
%\gamma_{m_i,j}^{n_i}
%= 2\sum_{i=1}^n\tau_i^2\Psi_{m_i}^{n_i}(m_i-1)\doublehat{\sigma}_{i,j}^2/m_i
%&+ \log(6n/p)\sum_i\tau_i^2D_{i,j}^2\Omega_{m_i}^{n_i}\Psi_{m_i}^{n_i}  \\
%&+\log(3/p)\left(\max_i\tau_i^2{\Psi_{m_i}^{n_i}}^2D_{i,j}^2\right)
%\end{align*}

\end{theorem}
\begin{proof}
Squaring \eqref{big_equation} and applying it specifically to the $j$th component of all the vectors gives:
\begin{equation*}
\pr\left(\frac{\left(\sum_{i=1}^n\tau_i(\chi_{i,m_i}-\mu_i)\right)^2}{\log(6/p)} 
\ge \alpha_{j} 
+ \left(\sqrt{\beta_{j}} 
+ \sqrt{\gamma_{j}}\right)^2  \right)
\le p 
\end{equation*}
%$$ \p\left(\frac{\left(\sum_{i=1}^n\tau_i(\chi_{i,m_i,j}-\mu_{i,j})\right)^2}{\log(6/p)}\ge \begin{matrix*}[l]\sum_{i=1}^n\frac{4}{17}\Omega_{m_i}^{n_i}D_{i,j}^2\tau_i^2 \\ +\begin{pmatrix*}[l]\sqrt{\log(3/p)\left(\max_i\tau_i^2{\Psi_{m_i}^{n_i}}^2D_{i,j}^2\right)} \\ +\sqrt{\begin{matrix*}[l]2\sum_{i=1}^n\tau_i^2\Psi_{m_i}^{n_i}(m_i-1)\doublehat{\sigma}_{i,j}^2/m_i \\ + \log(6n/p)\sum_i\tau_i^2D_{i,j}^2\Omega_{m_i}^{n_i}\Psi_{m_i}^{n_i} \\ +\log(3/p)\left(\max_i\tau_i^2{\Psi_{m_i}^{n_i}}^2D_{i,j}^2\right)\end{matrix*}} \end{pmatrix*}^2\end{matrix*} \right)\le p $$
Taking a series of union bounds (Lemma~\ref{prob_union}) over $j$ gives result.
\end{proof}

The left hand side of the inequality in \eqref{big_equation2} is the square Euclidean distance between our weighted stratified sample vector estimate $\sum_{i=1}^n\tau_i\chi_{i,m_i}$ and the true mean stratified vector $\sum_{i=1}^n\tau_i\mu_{i}$.
In this context, an example sampling process might consist of sampling to maximally minimise the right hand side of the inequality (similar to our SEBM process, described in Section~\ref{sec:SEBMalgorithm}).
This formulation can be applied to more involved computational tasks that involve sampling data with multiple features or auxiliary variables.






Second, a potential use of our stratified sampling method is in improving the performance of \textit{stochastic gradient decent} (SGD) methods for training neural networks \citep{2016arXiv160904747R}.
Neural networks are trained by iteratively refining their parameters --- the weights and biases of the network --- against a cost function of the network's performance against training data.
One common method of training neural networks is gradient decent (GD).
In each iteration of GD, the derivative of how much a change in any parameter would influence the average performance of the network across the training data is calculated as a gradient vector.
Once this vector is calculated, each network parameter takes a small step in the direction of this gradient, to incrementally increase the performance of the network, 
and through many of these steps the network becomes trained.

However in many cases, the entire corpus of training data is not used in each iteration but only a fraction of the corpus is sampled (as a `batch' or `minibatch'), and the average gradient vector of improved performance across the samples of the batch is calculated as an approximation of the true gradient vector. 
This iterative process has been called SGD, where one of the hyperparameters is the size of the batches, see \cite{DBLP:journals/corr/KeskarMNST16,l.2018dont}.
In the context of supervised learning, each element of the training data is labelled with the desired output of the neural network for it, and these labels can serve to naturally stratify the training data; or the data can be stratified by other means too \citep{DBLP:journals/corr/ZhangKM17,DBLP:journals/corr/abs-1804-02772,2014arXiv1405.3080Z}.
In this setting, Equation~\ref{big_equation2} may be used to choose between samples of labelled training data, in order to sample batches that more-efficiently estimate of the performance gradient, and hence improve the efficiency of neural network training procedure.
This idea of `smart sampling' for neural network training is not particularly new, and our method is potentially compatible with other performance-enhancing techniques in the literature on neural networks \citep{10.1007/978-3-319-24486-0_21,article123123131}.





